{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To serialise models\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    if not os.path.isdir(IMAGES_PATH):\n",
    "        os.makedirs(IMAGES_PATH)\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "\n",
    "PROCESSED_PATH = os.path.join(PROJECT_ROOT_DIR, \"processed\")\n",
    "def save_processed(df, filename, extension=\"csv\"):\n",
    "    if not os.path.isdir(PROCESSED_PATH):\n",
    "        os.makedirs(PROCESSED_PATH)\n",
    "    path = os.path.join(PROCESSED_PATH, filename + \".\" + extension)\n",
    "    print(\"Saving processed dataset\", filename)\n",
    "    df.to_csv(path, index=False)\n",
    "    \n",
    "SUBMISSIONS_PATH = os.path.join(PROJECT_ROOT_DIR, \"submissions\")\n",
    "def save_submission(df, filename, extension=\"csv\"):\n",
    "    if not os.path.isdir(SUBMISSIONS_PATH):\n",
    "        os.makedirs(SUBMISSIONS_PATH)\n",
    "    path = os.path.join(SUBMISSIONS_PATH, filename + \".\" + extension)\n",
    "    print(\"Saving submission\", filename)\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "MODELS_PATH = os.path.join(PROJECT_ROOT_DIR, \"models\")\n",
    "def save_model(model, filename):\n",
    "    if not os.path.isdir(MODELS_PATH):\n",
    "        os.makedirs(MODELS_PATH)\n",
    "    path = os.path.join(MODELS_PATH, filename + \".\" + \"pkl\")\n",
    "    print(\"Saving model\", filename)\n",
    "    joblib.dump(model, path)\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Zomato Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path, file, sub_dir=None, ext=\"csv\", encoding=None):\n",
    "    filename = file + \".\" + ext\n",
    "    if sub_dir is not None:\n",
    "        csv_path = os.path.join(base_path, sub_dir, filename)\n",
    "    else:\n",
    "        csv_path = os.path.join(base_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Zomato ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USA</td>\n",
       "      <td>New York City</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USA</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country           City  Zomato ID\n",
       "0     USA  New York City        280\n",
       "1     USA  San Francisco        306\n",
       "2     USA  Washington DC        283\n",
       "3     USA        Chicago        292\n",
       "4     USA    Los Angeles        281"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_ids = load_data(\"Raw/\", \"zomato_city_ids\")\n",
    "city_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"0ce0b2e48571f88facd08f8efd3569aa\"\n",
    "ENTITY_TYPE = \"city\"\n",
    "SORT_BY = \"rating\"\n",
    "SORT_ORDER = \"desc\"\n",
    "RAW_FOLDER = \"Raw/\"\n",
    "PROCESSED_FOLDER = \"Processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_categories():\n",
    "    # Get all zomato categories.\n",
    "    # Categories are global and not unique to a specific country.\n",
    "    headers = {\"user-key\": API_KEY}\n",
    "    response=requests.get(\"https://developers.zomato.com/api/v2.1/categories\", headers=headers)\n",
    "    json_data = response.json()\n",
    "    \n",
    "    if not os.path.isdir(RAW_FOLDER):\n",
    "         os.makedirs(RAW_FOLDER)\n",
    "    file_name = \"categories.json\"\n",
    "    file_path = os.path.join(RAW_FOLDER, file_name)\n",
    "    \n",
    "    with open(file_path, 'w') as outfile:\n",
    "        json.dump(json_data, outfile)\n",
    "        \n",
    "    # return all the category id's for restaurant search function.  \n",
    "    cat_ids = [category[\"categories\"][\"id\"] for category in json_data[\"categories\"]]\n",
    "    return cat_ids\n",
    "        \n",
    "def get_establishment_type_for_city(city_id):\n",
    "    # Finding all establishment types in city_id and writing to file\n",
    "    headers = {\"user-key\": API_KEY}\n",
    "    params = {\"city_id\": city_id}\n",
    "    response=requests.get(\"https://developers.zomato.com/api/v2.1/establishments\", \n",
    "                          headers=headers, params=params)\n",
    "    json_data = response.json()\n",
    "       \n",
    "    if not os.path.isdir(RAW_FOLDER):\n",
    "         os.makedirs(RAW_FOLDER)    \n",
    "    file_name = \"establishment_types_\" + str(city_id) + \".\" + \"json\"\n",
    "    file_path = os.path.join(RAW_FOLDER, file_name)\n",
    "    \n",
    "    with open(file_path, 'w') as outfile:\n",
    "        json.dump(json_data, outfile)\n",
    "        \n",
    "    # return all the establishment type id's for restaurant search function.  \n",
    "    establishment_ids = [establishment[\"establishment\"][\"id\"] for establishment in json_data[\"establishments\"]]\n",
    "    return establishment_ids\n",
    "        \n",
    "def get_cuisine_type_for_city(city_id):\n",
    "    # Finding all cuisine types in Cape Town and writing to file\n",
    "    headers = {\"user-key\": API_KEY}\n",
    "    params = {\"city_id\": city_id}\n",
    "    response=requests.get(\"https://developers.zomato.com/api/v2.1/cuisines\", \n",
    "                          headers=headers, params=params)\n",
    "    json_data = response.json()\n",
    "    \n",
    "    if not os.path.isdir(RAW_FOLDER):\n",
    "         os.makedirs(RAW_FOLDER)    \n",
    "    file_name = \"cuisine_types_\" + str(city_id) + \".\" + \"json\"\n",
    "    file_path = os.path.join(RAW_FOLDER, file_name)\n",
    "    \n",
    "    with open(file_path, 'w') as outfile:\n",
    "        json.dump(json_data, outfile)\n",
    "        \n",
    "    # return all the cuisine type id's for restaurant search function.\n",
    "    cuisine_ids = [cuisine[\"cuisine\"][\"cuisine_id\"] for cuisine in json_data[\"cuisines\"]]\n",
    "    return cuisine_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_with_criteria(headers, city_id, file_path, iterable_list, iterable_name, is_item_list=False):\n",
    "    json_dump = []\n",
    "    \n",
    "    # if API is not expecting a list for iterable_name, then run through each value as as search criteria\n",
    "    if not is_item_list:        \n",
    "        for item in iterable_list:\n",
    "            start = 0\n",
    "            results_shown = 20\n",
    "            while results_shown != 0:                \n",
    "                params = {\"entity_id\": city_id, \"entity_type\": ENTITY_TYPE, \"start\": start, \n",
    "                          \"count\": 20, iterable_name: item,\"sort\": SORT_BY, \n",
    "                          \"order\": SORT_ORDER}\n",
    "                response=requests.get(\"https://developers.zomato.com/api/v2.1/search\", \n",
    "                                  headers=headers, params=params)\n",
    "\n",
    "                json_data = response.json()\n",
    "                results_shown = int(json_data.get(\"results_shown\", 0))\n",
    "\n",
    "                if results_shown == 0:\n",
    "                    break\n",
    "\n",
    "                # appending each dictionary to a list so that json.load() can process \n",
    "                # multiple dictionaries\n",
    "                json_dump.append(json.dumps(json_data))     \n",
    "\n",
    "                start += 20\n",
    "    \n",
    "    # otherwise pass the full list to iterable_name, such as cuisine's. \n",
    "    # note: initially it was attempted to run through the above loop for every cuisine type, but allowed API calls \n",
    "    # where exceeded for a single city download attempt. \n",
    "    else:\n",
    "        start = 0\n",
    "        results_shown = 20\n",
    "        while results_shown != 0:            \n",
    "            params = {\"entity_id\": city_id, \"entity_type\": ENTITY_TYPE, \"start\": start, \n",
    "                      \"count\": 20, iterable_name: iterable_list,\"sort\": SORT_BY, \n",
    "                      \"order\": SORT_ORDER}\n",
    "            response=requests.get(\"https://developers.zomato.com/api/v2.1/search\", \n",
    "                              headers=headers, params=params)\n",
    "\n",
    "            json_data = response.json()\n",
    "            results_shown = int(json_data.get(\"results_shown\", 0))\n",
    "\n",
    "            if results_shown == 0:\n",
    "                break\n",
    "\n",
    "            # appending each dictionary to a list so that json.load() can process \n",
    "            # multiple dictionaries\n",
    "            json_dump.append(json.dumps(json_data))     \n",
    "\n",
    "            start += 20\n",
    "        \n",
    "            \n",
    "    \n",
    "    # each dictionary must exist as a list object for json.load to read it correctly    \n",
    "    with open(file_path, 'w') as outfile:\n",
    "        outfile.write(\"[\")\n",
    "        count = 0\n",
    "        for item in json_dump:\n",
    "            outfile.write(item)\n",
    "            if count < len(json_dump)-1:\n",
    "                outfile.write(\",\")\n",
    "            count += 1\n",
    "        outfile.write(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurants(city_id, categories, establishment_types, cuisine_types):\n",
    "     # Find 100 top rated restaurants of each establishment type, category and cuisine type per city and write to file\n",
    "    headers = {\"user-key\": API_KEY}\n",
    "    \n",
    "    if not os.path.isdir(RAW_FOLDER):\n",
    "         os.makedirs(RAW_FOLDER)\n",
    "    \n",
    "    search_criteria = [\"Category\", \"Establishment Type\", \"Cuisine Type\"]\n",
    "    city_name = city_ids[city_ids[\"Zomato ID\"] == city_id][\"City\"].values[0]\n",
    "    \n",
    "    # Download restaurant for city by category\n",
    "#     print(\"Downloading restaurants for\", city_name, \"by\", search_criteria[0])\n",
    "#     file_name = \"restaurants_by_category_\" + str(city_id) + \".\" + \"json\"\n",
    "#     file_path = os.path.join(RAW_FOLDER, file_name)\n",
    "#     download_with_criteria(headers, city_id, file_path, categories, \"category\", is_item_list=False)\n",
    "#     print(\"Done\")\n",
    "\n",
    "    # Download restaurant for city by establishment type\n",
    "    print(\"Downloading restaurants for\", city_name, \"by\", search_criteria[1])\n",
    "    file_name = \"restaurants_by_establishment_type_\" + str(city_id) + \".\" + \"json\"\n",
    "    file_path = os.path.join(RAW_FOLDER, file_name)\n",
    "    download_with_criteria(headers, city_id, file_path, establishment_types, \"establishment_type\", is_item_list=False)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    # Download restaurant for city by cuisine type\n",
    "#     print(\"Downloading restaurants for\", city_name, \"by\", search_criteria[2])\n",
    "#     file_name = \"restaurants_by_cuisine_type_\" + str(city_id) + \".\" + \"json\"\n",
    "#     file_path = os.path.join(RAW_FOLDER, file_name)\n",
    "#     download_with_criteria(headers, city_id, file_path, cuisine_types, \"cuisines\", is_item_list=True)\n",
    "#     print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = get_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading restaurants for Cape Town by Establishment Type\n",
      "Done\n",
      "Downloading restaurants for Rio De Janeiro by Establishment Type\n",
      "Done\n",
      "Downloading restaurants for Sao Paulo by Establishment Type\n",
      "Done\n",
      "Downloading restaurants for Santiago by Establishment Type\n",
      "Done\n",
      "Downloading restaurants for Dubai by Establishment Type\n",
      "Done\n",
      "Downloading restaurants for Doha by Establishment Type\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for city_id in cities:\n",
    "    establishments = get_establishment_type_for_city(city_id)\n",
    "    #cuisines = get_cuisine_type_for_city(city_id)\n",
    "    get_restaurants(city_id, None, establishments, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each city, we need to combine the restaurant data from the categories-based, establishment type-based and cuisine-based json files. \n",
    "\n",
    "def build_csv(city_id, source_type):\n",
    "    file_name = \"restaurants_by_\" + source_type + \"_\" + str(city_id) + \".json\"\n",
    "    source_path = os.path.join(RAW_FOLDER, file_name)\n",
    "    \n",
    "    db = json.load(open(source_path))\n",
    "    \n",
    "    restaurant_cols = [\"name\", \n",
    "                       \"cuisines\",\n",
    "                       \"aggregate_rating\", \n",
    "                       \"rating_text\", \n",
    "                       \"votes\",\n",
    "                       \"currency\", \n",
    "                       \"average_cost_for_two\", \n",
    "                       \"price_range\",                    \n",
    "                       \"locality\",\n",
    "                       \"locality_verbose\",\n",
    "                       \"city\", \n",
    "                       \"zipcode\",\n",
    "                       \"country_id\",\n",
    "                       \"latitude\", \n",
    "                       \"longitude\",                                       \n",
    "                       \"has_online_delivery\", \n",
    "                       \"has_table_booking\", \n",
    "                       ]\n",
    "    \n",
    "    restaurants = [restaurant_group[\"restaurant\"] for count_group in db \n",
    "                       for restaurant_group in count_group[\"restaurants\"]] \n",
    "    \n",
    "    for restaurant in restaurants:\n",
    "        restaurant[\"locality\"] = restaurant[\"location\"][\"locality\"]\n",
    "        restaurant[\"locality_verbose\"] = restaurant[\"location\"][\"locality_verbose\"]\n",
    "        restaurant[\"city\"] = restaurant[\"location\"][\"city\"]\n",
    "        restaurant[\"latitude\"] = restaurant[\"location\"][\"latitude\"]\n",
    "        restaurant[\"longitude\"] = restaurant[\"location\"][\"longitude\"]\n",
    "        restaurant[\"zipcode\"] = restaurant[\"location\"][\"zipcode\"]\n",
    "        restaurant[\"country_id\"] = restaurant[\"location\"][\"country_id\"]\n",
    "        restaurant[\"aggregate_rating\"] = restaurant[\"user_rating\"][\"aggregate_rating\"]\n",
    "        restaurant[\"votes\"] = restaurant[\"user_rating\"][\"votes\"]\n",
    "        restaurant[\"rating_text\"] = restaurant[\"user_rating\"][\"rating_text\"]\n",
    "        \n",
    "    \n",
    "    df = pd.DataFrame(restaurants, columns=restaurant_cols)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def process_restaurants_json(city_id):\n",
    "    \n",
    "    #source_types = [\"category\", \"cuisine_type\", \"establishment_type\"]\n",
    "    source_types = [\"establishment_type\"]\n",
    "    dfs = []\n",
    "    for source in source_types:\n",
    "        dfs.append(build_csv(city_id, source))\n",
    "    \n",
    "    if not os.path.isdir(PROCESSED_FOLDER):\n",
    "         os.makedirs(PROCESSED_FOLDER) \n",
    "    \n",
    "    file_name = \"restaurants_\" + str(city_id) + \".csv\"\n",
    "    output_path = os.path.join(PROCESSED_FOLDER, file_name)\n",
    "\n",
    "    data = pd.concat(dfs)\n",
    "    data.to_csv(output_path, encoding='utf-8-sig', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_ids = load_data(\"Raw/\", \"zomato_city_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in city_ids[\"Zomato ID\"]:\n",
    "    process_restaurants_json(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
